"""
High level module containing code for loading a DagFactory config
and generating DAGs.
"""

import logging
import os
from itertools import chain
from pathlib import Path
from typing import Any, Dict, Iterable, List, Union

import yaml
from dagfactory.dagbuilder import DagBuilder
from dagfactory.exceptions import DagFactoryConfigException, DagFactoryException

from airflow.configuration import conf as airflow_conf
from airflow.models import DAG

# these are params that cannot be a dag name
SYSTEM_PARAMS: List[str] = ["default", "task_groups"]


class DagFactory:
    """

    Takes a YAML config and generates DAGs.

    !! For None values in config, use 'null' in YAML !!

    Args:
        config_filepath: Path to YAML config file. Must be absolute.

    """

    def __init__(self, config_filepath: str) -> None:
        DagFactory._validate_config_filepath(config_filepath)

        self.config: Dict[str, Any] = DagFactory._load_config(config_filepath)

    @staticmethod
    def _validate_config_filepath(config_filepath: str) -> None:
        """
        Validates config file path is absolute

        Args:
            config_filepath: Path to YAML config file.

        Raises:
            DagFactoryConfigException: if config_filepath is not absolute

        """
        if not os.path.isabs(config_filepath):
            raise DagFactoryConfigException('DAG Factory "config_filepath" must be absolute path')

    @staticmethod
    def _load_config(config_filepath: str) -> Dict[str, Any]:
        """
        Loads YAML config file

        Raises:
            DagFactoryConfigException: if config file is invalid

        Returns:
            Dict of config.
        """
        try:
            with open(config_filepath, "r", encoding="utf-8") as config_file:
                config = yaml.safe_load(config_file)
        except Exception as exc:
            logging.error("Invalid DAG Factory config file: %s", str(exc))
            raise DagFactoryConfigException("Invalid DAG Factory config file") from exc

        return config

    def get_dag_configs(self) -> Dict[str, Dict[str, Any]]:
        """
        Returns configuration for each the DAG in factory

        Returns:
            dict with configuration for dags
        """
        return {dag: self.config[dag] for dag in self.config.keys() if dag not in SYSTEM_PARAMS}

    def get_default_config(self) -> Dict[str, Any]:
        """
        Get default parameters for dag factory.

        Returns:
            dict with default configuration
        """
        return self.config.get("default", {})

    def build_dags(self) -> Dict[str, DAG]:
        """
        Build DAGs from config.
        """
        dag_configs: Dict[str, Dict[str, Any]] = self.get_dag_configs()
        default_config: Dict[str, Any] = self.get_default_config()

        dags: Dict[str, Any] = {}

        for dag_name, dag_config in dag_configs.items():
            # Make sure 'task_groups' is member of dag_config
            dag_config["task_groups"] = dag_config.get("task_groups", {})
            dag_builder: DagBuilder = DagBuilder(
                dag_name=dag_name,
                dag_config=dag_config,
                default_config=default_config,
            )
            try:
                dag: Dict[str, Union[str, DAG]] = dag_builder.build()
                dags[dag["dag_id"]] = dag["dag"]  # type: ignore
                logging.info("Created DAG with id %s", dag["dag_id"])
            except Exception as err:
                logging.error("Failed to generate dag %s : %s", dag_name, str(err))
                raise DagFactoryException("Failed to generate dag. Verify config is correct.") from err

        return dags

    # pylint: disable=redefined-builtin
    @staticmethod
    def register_dags(dags: Dict[str, DAG], globals: Dict[str, Any]) -> None:
        """
        Adds DAGs to globals so they can be discovered by Airflow.

        Args:
            dags: Dict of DAGs to register.
            globals: globals() to add DAGs to.
        """
        for dag_id, dag in dags.items():
            globals[dag_id] = dag

    def generate_dags(self, globals: Dict[str, Any]) -> None:
        """
        Generates DAGs from YAML config and registers them in global scope.

        Args:
            globals: globals() to add DAGs to.
        """
        dags: Dict[str, Any] = self.build_dags()
        self.register_dags(dags, globals)

    def clean_dags(self, globals: Dict[str, Any]) -> None:
        """
        Clean old DAGs that are not on yaml config but where
        generated by dag-factory.

        Args:
            globals: globals() to clean DAGs from.
        """
        dags: Dict[str, Any] = self.build_dags()

        dags_in_globals: Dict[str, Any] = {}
        for k, glb in globals.items():
            if isinstance(glb, DAG) and hasattr(glb, "is_dagfactory_auto_generated"):
                dags_in_globals[k] = glb

        dags_to_remove: List[str] = list(set(dags_in_globals) - set(dags))

        # removing from DagBag
        for dag_to_remove in dags_to_remove:
            del globals[dag_to_remove]

    # pylint: enable=redefined-builtin


def load_yaml_dags(
    globals_dict: Dict[str, Any],
    dags_folder: str = airflow_conf.get("core", "dags_folder"),
    suffix: List[str] | None = None,
) -> None:
    """
    Load all the YAML files in the DAGs folder.
    One DagFactory is created per YAML file.

    Args:
        globals_dict: globals() to add DAGs to.
        dags_folder: Path to DAGs folder. Defaults to Airflow DAGs folder.
        suffix: Suffix of the YAML files to load. Defaults to .yaml and .yml.
    """
    # chain all file suffixes in a single iterator
    logging.info("Loading DAGs from %s", dags_folder)
    if suffix is None:
        suffix = [".yaml", ".yml"]
    candidate_dag_files: Iterable[Path] = []
    for suf in suffix:
        candidate_dag_files = chain(candidate_dag_files, Path(dags_folder).rglob(f"*{suf}"))

    for config_file_path in candidate_dag_files:
        config_file_abs_path = str(config_file_path.absolute())
        DagFactory(config_file_abs_path).generate_dags(globals_dict)
        logging.info("DAG(s) loaded: %s", config_file_path)
